{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "df = pd.read_csv(\"inputs-for-ml/final_ml_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "X = df[[\"slope\", \"elevation\", \"north_gps\", \"east_gps\", \"vertical_gps\", \"coherence\",\"los_insar\"]]\n",
    "y = df[\"bias\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define regression models\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Support Vector Regression\": SVR(),\n",
    "    \"Neural Network Regression\": MLPRegressor(hidden_layer_sizes=(100,), max_iter=1000, random_state=42),\n",
    "    \"Decision Tree Regression\": DecisionTreeRegressor(random_state=42),\n",
    "    \"Random Forest Regression\": RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting Regression\": GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize performance list\n",
    "performance_list = []\n",
    "\n",
    "# Train and evaluate models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    performance_list.append({\"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "    # Plot predicted vs actual and Q-Q plot\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "    # Scatter plot: Predicted vs Actual\n",
    "    sns.regplot(\n",
    "        x=y_test, y=y_pred,\n",
    "        scatter_kws={\"s\": 20},\n",
    "        line_kws={\"color\": \"red\", \"linestyle\": \"--\"},\n",
    "        ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_xlabel(\"Actual Bias\")\n",
    "    axes[0].set_ylabel(\"Predicted Bias\")\n",
    "    axes[0].set_title(f\"{name} - Predicted vs Actual\")\n",
    "    axes[0].grid(True)\n",
    "    axes[0].set_aspect('equal', adjustable='box')\n",
    "\n",
    "    textstr = f\"RMSE: {rmse:.3f}\\nRÂ²: {r2:.3f}\"\n",
    "    axes[0].text(\n",
    "        0.05, 0.95, textstr,\n",
    "        transform=axes[0].transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.7)\n",
    "    )\n",
    "\n",
    "    # Q-Q plot: Residuals\n",
    "    residuals = y_test - y_pred\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[1])\n",
    "    axes[1].get_lines()[1].set_color('red')\n",
    "    axes[1].set_xlabel(\"Actual Bias Quantiles\")\n",
    "    axes[1].set_ylabel(\"Estimated Bias Quantiles\")\n",
    "    axes[1].set_title(f\"{name} - Q-Q Plot of Residuals\")\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    plt.suptitle(f\"{name} - Performance Analysis\", fontsize=14, weight='bold')\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95], w_pad=4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create performance DataFrame\n",
    "performance_df = pd.DataFrame(performance_list)\n",
    "\n",
    "# Clean and format columns\n",
    "performance_df.rename(columns=lambda x: x.strip().upper(), inplace=True)\n",
    "performance_df = performance_df.round({\"RMSE\": 3, \"R2\": 3})\n",
    "performance_df = performance_df.sort_values(by=\"R2\", ascending=False).reset_index(drop=True)\n",
    "performance_df.index += 1\n",
    "performance_df.index.name = \"Rank\"\n",
    "\n",
    "# Print performance table\n",
    "print(performance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extended Hyperparameter Tuning for All Models\n",
    "\n",
    "# Redefine models with hyperparameter grids\n",
    "param_grids = {\n",
    "    \"Ridge Regression\": {\n",
    "        \"model\": RidgeCV(alphas=[0.1, 1.0, 10.0], cv=5),\n",
    "        \"tune\": False\n",
    "    },\n",
    "    \"Support Vector Regression\": {\n",
    "        \"model\": SVR(),\n",
    "        \"params\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"epsilon\": [0.01, 0.1, 0.2],\n",
    "            \"kernel\": [\"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"Neural Network Regression\": {\n",
    "        \"model\": MLPRegressor(max_iter=1000, random_state=42),\n",
    "        \"params\": {\n",
    "            \"hidden_layer_sizes\": [(50,), (100,), (100, 50)],\n",
    "            \"alpha\": [0.0001, 0.001],\n",
    "            \"learning_rate_init\": [0.001, 0.01]\n",
    "        }\n",
    "    },\n",
    "    \"Decision Tree Regression\": {\n",
    "        \"model\": DecisionTreeRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Random Forest Regression\": {\n",
    "        \"model\": RandomForestRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    \"Gradient Boosting Regression\": {\n",
    "        \"model\": GradientBoostingRegressor(random_state=42),\n",
    "        \"params\": {\n",
    "            \"n_estimators\": [50, 100, 200],\n",
    "            \"learning_rate\": [0.01, 0.1],\n",
    "            \"max_depth\": [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize dictionaries to store best models and importances\n",
    "best_models = {}\n",
    "feature_importance_dict = {}\n",
    "\n",
    "# Iterate over models and tune\n",
    "for name, settings in param_grids.items():\n",
    "    model = settings[\"model\"]\n",
    "    \n",
    "    if settings.get(\"tune\", True):\n",
    "        grid_search = GridSearchCV(model, settings[\"params\"], cv=5, scoring=\"r2\", n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        best_model = model\n",
    "\n",
    "    best_models[name] = best_model\n",
    "\n",
    "    # Feature Importance\n",
    "    if hasattr(best_model, \"feature_importances_\"):\n",
    "        feature_importance_dict[name] = best_model.feature_importances_\n",
    "    elif hasattr(best_model, \"coef_\"):\n",
    "        feature_importance_dict[name] = np.abs(best_model.coef_)\n",
    "    else:\n",
    "        # Use permutation importance for models that don't have built-in importance\n",
    "        result = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=42, n_jobs=-1)\n",
    "        feature_importance_dict[name] = result.importances_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect and Display Feature Importances\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance_df = pd.DataFrame(feature_importance_dict, index=df[[\"slope\", \"elevation\", \"north_gps\", \"east_gps\", \"vertical_gps\", \"coherence\", \"los_insar\"]].columns)\n",
    "\n",
    "# Normalize feature importance values for comparison\n",
    "feature_importance_df = feature_importance_df.div(feature_importance_df.sum(axis=0), axis=1)\n",
    "\n",
    "# Plot feature importances\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "feature_importance_df.plot(kind=\"barh\", ax=ax)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance Comparison Across Models\", fontsize=14, weight='bold')\n",
    "plt.xlabel(\"Normalized Importance Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print feature importance table\n",
    "print(feature_importance_df.round(3))\n",
    "\n",
    "# Re-Evaluate Tuned Model Performances\n",
    "\n",
    "# Initialize new performance list\n",
    "performance_list_tuned = []\n",
    "\n",
    "# Evaluate all tuned models\n",
    "for name, model in best_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    performance_list_tuned.append({\"Model\": name, \"RMSE\": rmse, \"R2\": r2})\n",
    "\n",
    "# Create performance DataFrame\n",
    "performance_df_tuned = pd.DataFrame(performance_list_tuned)\n",
    "performance_df_tuned.rename(columns=lambda x: x.strip().upper(), inplace=True)\n",
    "performance_df_tuned = performance_df_tuned.round({\"RMSE\": 3, \"R2\": 3})\n",
    "performance_df_tuned = performance_df_tuned.sort_values(by=\"R2\", ascending=False).reset_index(drop=True)\n",
    "performance_df_tuned.index += 1\n",
    "performance_df_tuned.index.name = \"Rank\"\n",
    "\n",
    "# Print tuned performance table\n",
    "print(\"\\nTuned Model Performance:\")\n",
    "print(performance_df_tuned)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
